# -*- coding: utf-8 -*-
"""SQLConvertor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gkvbqB0Jd3bpowHHO5zlbwxTZa-XzRWS
"""

!pip install simple-ddl-parser
!pip install nltk

import tensorflow_hub as hub
from simple_ddl_parser import DDLParser
import json
import nltk
import pandas as pd
from scipy.spatial import distance



from nltk.corpus import words
from nltk.corpus import stopwords
nltk.download('all')

#list of all words from english dictionary
import nltk
#list of all words from english dictionary

nltk.download('words')

from nltk.corpus import words
from nltk.corpus import stopwords

wordslist = list(set(words.words('en')))
#print("The word list " + str(wordslist))

#list of all english stopwords
stops = list(set(stopwords.words('english')))

## Common words in nltk data set  
alphabets = [chr(x) for x in range(ord('a'), ord('z') + 1)]
cleaned_word_list = list(set(wordslist)|set(stops))
#cleaned_word_list = list(set(stops))
cleaned_word_list = list(set(cleaned_word_list)|set(alphabets))
cleaned_word_dict = dict((i, 0) for i in cleaned_word_list)

## Create Table Syntax in Oracle 
oracle_ddl = """CREATE TABLE customers
(
   cust_id                  NUMBER         NOT NULL,
   cust_first_name          VARCHAR2(20)   NOT NULL,
   cust_last_name           VARCHAR2(40)   NOT NULL,
   cust_gender              CHAR(1)        NOT NULL,
   cust_year_of_birth       NUMBER(4)      NOT NULL,
   cust_marital_status      VARCHAR2(20),
   cust_street_address      VARCHAR2(40)   NOT NULL,
   cust_postal_code         VARCHAR2(10)   NOT NULL,
   cust_city                VARCHAR2(30)   NOT NULL,
   cust_city_id             NUMBER         NOT NULL,
   cust_state_province      VARCHAR2(40)   NOT NULL,
   cust_state_province_id   NUMBER         NOT NULL,
   country_id               NUMBER         NOT NULL,
   cust_main_phone_number   VARCHAR2(25)   NOT NULL,
   cust_income_level        VARCHAR2(30),
   cust_credit_limit        NUMBER,
   cust_email               VARCHAR2(50),
   cust_total               VARCHAR2(14)   NOT NULL,
   cust_total_id            NUMBER         NOT NULL,
   cust_src_id              NUMBER,
   cust_eff_from            DATE,
   cust_eff_to              DATE,
   cust_valid               VARCHAR2(1),
   CONSTRAINT customers_pk
      PRIMARY KEY (cust_id),
   CONSTRAINT customers_country_fk
      FOREIGN KEY (country_id) REFERENCES countries (country_id)
);"""

oracle_data_result = DDLParser(oracle_ddl).run(output_mode="oracle",json_dump=True)
#print(oracle_data_result)

## Create Table Syntax in Postgres 
postgres_ddl = """CREATE TABLE customers
(
   cu-id                  numeric         NOT NULL,
   cu-firstname          VARCHAR   NOT NULL,
   cu_last_name           VARCHAR   NOT NULL,
   cu-gender              CHAR       NOT NULL,
   cu-birth-year       numeric      NOT NULL,
   cu-is-married      VARCHAR,
   cu-street-address      VARCHAR   NOT NULL,
   cu-postal-code         VARCHAR   NOT NULL,
   cu-city                VARCHAR   NOT NULL,
   cu-city-id             NUMBER         NOT NULL,
   cu-state-province      VARCHAR   NOT NULL,
   cu-state-province-id   numeric         NOT NULL,
   cu-country-code               numeric         NOT NULL,
   cu-telephone-number   VARCHAR   NOT NULL,
   cu-income-data        VARCHAR,
   cu-credit-data        numeric,
   cu-email               VARCHAR,
   cu-total               VARCHAR   NOT NULL,
   cu-total-id            numeric         NOT NULL,
   cu-src-id              numeric,
   cu-from            DATE,
   cu-to              DATE,
   cu-valid               VARCHAR
);"""

postgres_data_result = DDLParser(postgres_ddl).run(output_mode="postgres",json_dump=True)
#print(postgres_data_result)

def extract_words(x):
    res = []
    subs = [x[i:j+1] for i in range(len(x)) for j in range(i,len(x))if (i - (j+1)) < -1]
    for sub in subs:
        try:
            l = cleaned_word_dict[sub]
            res.append(str(sub))
        except:
            pass
    return sorted(res, key = len, reverse=True)

def filter_words(x):
  data = extract_words(x)
  res = []
  for sub in data:
     if len(res)== 0:
      res.append(str(sub))
     else:
      result = []
      for uniq in res:
        if (uniq.find(str(sub)) > -1) :
            result.append(str(sub))
      if (len(result) == 0) :
        res.append(str(sub))
  listToStr = ' '.join([str(elem) for elem in res])
  return listToStr

#data = extract_words("_year_of_birth")
#filter = filter_words(data)
#print(str(filter))

# Use Sentence encoder for Embedding 
embed = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")
def getdistance(data1,data2) :
  embeddings = embed([
    data1,
    data2
    ])
  return 1 - distance.cosine(embeddings[0], embeddings[1])

## Create Comparision report 
def mapdata(firstdataset,seconddataset):
  first_data = json.loads(firstdataset)
  second_data=json.loads(seconddataset)
  total_df =  pd.DataFrame(columns=['oracle_column', 'postgres_column', 'similarity'])
  iter = 0
  for i in first_data[0]['columns']:
     rows_list = []
     df_temp =  pd.DataFrame(columns=['oracle_column', 'postgres_column', 'similarity'])
     for j in second_data[0]['columns']:
      if  (str(i['type']).lower() == "number"  and str(j['type']).lower() == "numeric"):
        dict1 = {}
        #test_str.replace('cust', ' ')
        fdata = filter_words(str(i['name']).lower().replace('cust', ' '))
        sdata = filter_words(str(j['name']).lower().replace('cu', ' '))
        distance = getdistance(fdata,sdata)
        dict1.update(oracle_column=str(i['name']),postgres_column=str(j['name']),similarity=distance)
        rows_list.append(dict1)
      elif "varchar" in str(i['type']).lower()  and str(j['type']).lower() == "varchar":
        dict1 = {}
        fdata = filter_words(str(i['name']).lower().replace('cust', ' '))
        sdata = filter_words(str(j['name']).lower().replace('cu', ' '))
        distance = getdistance(fdata,sdata)
        dict1.update(oracle_column=str(i['name']),postgres_column=str(j['name']),similarity=distance)
        rows_list.append(dict1)
      elif str(i['type']).lower() == "char"  and str(j['type']).lower() == "char":
        dict1 = {}
        fdata = filter_words(str(i['name']).lower().replace('cust', ' '))
        sdata = filter_words(str(j['name']).lower().replace('cu', ' '))
        distance = getdistance(fdata,sdata)
        dict1.update(oracle_column=str(i['name']),postgres_column=str(j['name']),similarity=distance)
        rows_list.append(dict1)
      elif str(i['type']).lower() == "date"  and  str(j['type']).lower() == "date":
        dict1 = {}
        fdata = filter_words(str(i['name']).lower().replace('cust', ' '))
        sdata = filter_words(str(j['name']).lower().replace('cu', ' '))
        distance = getdistance(fdata,sdata)
        dict1.update(oracle_column=str(i['name']),postgres_column=str(j['name']),similarity=distance)
        rows_list.append(dict1)
     df_temp = pd.DataFrame(rows_list)
     df1 = df_temp.sort_values("similarity", ascending=False).head(1)
     total_df = pd.concat([total_df,df1])
  return total_df

df = mapdata(oracle_data_result,postgres_data_result)
# Write Report 
df.to_excel('/content/sample_data/compare_report.xlsx',index=False)

