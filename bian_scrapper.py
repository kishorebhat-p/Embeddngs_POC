# -*- coding: utf-8 -*-
"""webscrapers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/190jf0c0tMdL57T69NF2QjBWqZIfT5vjr
"""

!pip install requests
!pip install html5lib
!pip install bs4

#This will not run on online IDE
import requests
import pandas as pd
from bs4 import BeautifulSoup

URL = "https://bian.org/semantic-apis/"
r = requests.get(URL)

soup = BeautifulSoup(r.content, 'html5lib') # If this line causes an error, run 'pip install html5lib' or install html5lib

df = pd.DataFrame(columns=['Name','Link'])


for link in soup.find_all('a'):
  if ("semantic-apis" in str(link.get('href'))):
    df1 = pd.DataFrame({'Name': [link.get_text()],
                    'Link': [link.get('href')]})
    df = pd.concat([df, df1],axis = 0,ignore_index=True)


substring = 'Swagger'

def isNotBlank (myString):
    return bool(myString and myString.strip())

def getUrlContent(url) :
  req = requests.get(url)
  print("executing for " + url)
  soup = BeautifulSoup(req.content, 'html5lib')
  returnStr = ""
  for link in soup.find_all("div", class_="col-xs-12 col-md-9 col-md-offset-1"):
    for plink in link.findAll("p", class_="p3"):
      if ((substring not in plink.get_text()) & (isNotBlank(plink.get_text()))) :
        returnStr = returnStr + plink.get_text().strip() +  " . "
    for lilink in link.findAll('li') :
      returnStr = returnStr +  lilink.get_text().strip() + " . "
    return returnStr

df['content'] = df.apply(lambda x: getUrlContent(x.Link), axis=1)

df = df.drop(df[df['Name'] == 'How to use this portal?'].index)

df.to_excel("bian_data_v2.xlsx")
