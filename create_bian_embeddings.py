# -*- coding: utf-8 -*-
"""UBS_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QLjxzYchD6cIzbNb2zid_oXXodTBTloY
"""

#!pip install openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken

import openai
import os
import re
import requests
import sys
from num2words import num2words
import os
import pandas as pd
import numpy as np
from openai.embeddings_utils import get_embedding, cosine_similarity
import tiktoken


openai.api_type = "azure"
openai.api_base = "https://openai-pocfsstar.openai.azure.com/"
openai.api_version = "2022-12-01"
os.environ["OPENAI_API_KEY"] = "*********************************"
openai.api_key = os.getenv("OPENAI_API_KEY")




df=pd.read_excel('./bian_data_v2.xlsx')


import re
def normalize_text(s, sep_token = " \n "):
    s = re.sub(r'\s+',  ' ', s).strip()
    s = re.sub(r". ,","",s)
    # remove all instances of multiple spaces
    s = s.replace("..",".")
    s = s.replace(". .",".")
    s = s.replace("\n", "")
    s = s.replace("-", "")
    s = s.strip()
    return s

def remove(string):
    return string.replace(" ", "")

df['Filename'] = df.apply(lambda x: remove(x.Name), axis=1)

df['content']= df['content'].apply(lambda x : normalize_text(x))

print(len(df))
print("done")


import time
results = []
for ind in df.index:
   text=df['content'][ind]
   embed = get_embedding(text, engine = 'star-embedding-ada')
   filename= "./bianembed/" + str(df['Filename'][ind]) + ".txt"
   embed = get_embedding(text, engine = 'star-embedding-ada')
   np.save(filename,embed)
   results.append(embed)
   time.sleep(3)
   print("Done with " + str(ind))
